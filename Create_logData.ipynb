{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load JSON function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJson(path):\n",
    "    with open(path,'r') as fp: \n",
    "        data_json = json.load(fp)\n",
    "        return (data_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data Frame function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDataFrame(df,path):\n",
    "    '''save DataFerame in csv format'''\n",
    "    df.to_csv(path,sep=',',index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON to Data Frame function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getData(l):\n",
    "    instance = []\n",
    "    usage = []\n",
    "    timestamps = []\n",
    "    \n",
    "    for t in l:\n",
    "        if t != []:\n",
    "            idata = t[0]\n",
    "            for h in (idata['datapoints']):\n",
    "                target = idata['target']\n",
    "                target = re.sub('\\_com.*', '', target)\n",
    "                target = target+'_com'\n",
    "                instance.append(target)\n",
    "                usage.append(h[0])\n",
    "                timestamps.append(h[1])\n",
    "        else:\n",
    "            instance.append(np.nan)\n",
    "            usage.append(np.nan)\n",
    "            timestamps.append(np.nan)\n",
    "    df = pd.DataFrame({'instance': instance, 'usage':usage, 'timestamp':timestamps})\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading cpu logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = './logs/cpu'\n",
    "save_to = './dataframes/'\n",
    "pathlist = Path(load_from).glob('*.json')\n",
    "df_cpu = pd.DataFrame()\n",
    "for p in pathlist:\n",
    "    jsonData = loadJson(p)\n",
    "    dayDF = getData(jsonData)\n",
    "    df_cpu = df_cpu.append(dayDF)\n",
    "    saveDataFrame(df_cpu,path=save_to+'cpu.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading network in logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = './logs/network/inb'\n",
    "save_to = './dataframes/'\n",
    "pathlist = Path(load_from).glob('*.json')\n",
    "df_nwin = pd.DataFrame()\n",
    "for p in pathlist:\n",
    "    jsonData = loadJson(p)\n",
    "    dayDF = getData(jsonData)\n",
    "    df_nwin = df_nwin.append(dayDF)\n",
    "    saveDataFrame(df_nwin,path=save_to+'nwin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading network out logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = './logs/network/outb'\n",
    "save_to = './dataframes/'\n",
    "pathlist = Path(load_from).glob('*.json')\n",
    "df_nwout = pd.DataFrame()\n",
    "for p in pathlist:\n",
    "    jsonData = loadJson(p)\n",
    "    dayDF = getData(jsonData)\n",
    "    df_nwout = df_nwout.append(dayDF)\n",
    "    saveDataFrame(df_nwout,path=save_to+'nwout.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty fields\n",
    "df_cpu_clean = df_cpu.dropna(axis=0, how='all',subset=['instance','usage','timestamp'])\n",
    "df_nwin_clean = df_nwin.dropna(axis=0, how='all',subset=['instance','usage','timestamp'])\n",
    "df_nwout_clean = df_nwout.dropna(axis=0, how='all',subset=['instance','usage','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all 3 dataframes\n",
    "cpu_nwin = pd.merge(df_cpu_clean, df_nwin_clean, how='inner', on= ['instance','timestamp'], suffixes=['_cpu','_nwin'])\n",
    "logData = pd.merge(cpu_nwin, df_nwout_clean, how='inner', on= ['instance','timestamp'])\n",
    "\n",
    "# rename to usage nwout\n",
    "logData.rename(columns={'usage': 'usage_nwout'}, inplace=True) \n",
    "\n",
    "# create readable date column from timestamp\n",
    "logData['date'] = logData.timestamp.apply(lambda x: datetime.datetime.fromtimestamp(x).strftime('%Y-%m-%d %X'))\n",
    "\n",
    "# clean instance name\n",
    "logData.instance = logData.instance.apply(lambda x: re.sub(r'.+EC2.','', x))\n",
    "logData.instance = logData.instance.apply(lambda x: re.sub('_','.', x))\n",
    "\n",
    "# reorder\n",
    "logData = logData[['instance', 'timestamp', 'date', 'usage_cpu', 'usage_nwin', 'usage_nwout']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at data range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169923"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of records\n",
    "len(logData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of instances we have log data for\n",
    "len(logData.instance.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of instances we have log data for\n",
    "len(df_cpu_clean.instance.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of instances we have log data for\n",
    "len(df_nwin_clean.instance.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of instances we have log data for\n",
    "len(df_nwout_clean.instance.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.958333333333334"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Date range\n",
    "aux = logData.sort_values(by='timestamp', ascending=False)\n",
    "aux = aux.reset_index(drop=True)\n",
    "\n",
    "dlast = aux.timestamp[0]\n",
    "dfirst = aux.timestamp[len(aux.timestamp)-1]\n",
    "days_range = (dlast-dfirst)/(3600*24)\n",
    "days_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDataFrame(logData, path='./dataframes/logData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access a field (first column then row)\n",
    "# df['instance'][87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_from = \"./logs/cpu/cpu_1.json\"\n",
    "# with open(load_from,'r') as fp: \n",
    "#         data_json = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(data_json)):\n",
    "#     if data_json[i]!= []:\n",
    "#         print(data_json[i][0]['datapoints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Same as above but trying to input it in a Dataframe directly\n",
    "# def getData(l):\n",
    "#     df = pd.DataFrame()\n",
    "#     df['instance'] = np.NaN\n",
    "#     df['usage'] = np.NaN\n",
    "#     df['timestamp'] = np.NaN\n",
    "#     for t in l:\n",
    "#         if t != []:\n",
    "#             usage = []\n",
    "#             timestamps = []\n",
    "#             idata = t[0]\n",
    "#             df['instance'] = idata['target']*len(idata['datapoints'])\n",
    "#             for h in (idata['datapoints']):\n",
    "#                 usage.append(h[0])\n",
    "#                 timestamps.append(h[1])\n",
    "#             df['usage'] = usage\n",
    "#             df['timestamp'] = timestamps\n",
    "#     return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different test i did\n",
    "\n",
    "# def getData(l):\n",
    "#     instance = []\n",
    "#     usage = []\n",
    "#     timestamps = []\n",
    "#     for t in l:\n",
    "#         if t != []:\n",
    "#             usage = []\n",
    "#             timestamps = []\n",
    "#             idata = t[0]\n",
    "#             instance = idata['target']\n",
    "#             for h in (idata['datapoints']):\n",
    "#                 usage.append(h[0])\n",
    "#                 timestamps.append(h[1])\n",
    "#         c = [instance, usage, timestamps]\n",
    "#     return (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Same as above but trying to input it in a Dataframe directly\n",
    "# def getData(l):\n",
    "# #     df = pd.DataFrame()\n",
    "# #     df['instance'] = np.NaN\n",
    "# #     df['usage'] = np.NaN\n",
    "# #     df['timestamp'] = np.NaN\n",
    "#     instance = []\n",
    "#     usage = []\n",
    "#     timestamps = []\n",
    "    \n",
    "#     for t in l:\n",
    "#         if t != []:\n",
    "# #             instance = []\n",
    "# #             usage = []\n",
    "# #             timestamps = []\n",
    "#             idata = t[0]\n",
    "#             #df['instance'] = idata['target']*len(idata['datapoints'])\n",
    "#            # instance.append(idata['target']*len(idata['datapoints']))\n",
    "#             for h in (idata['datapoints']):\n",
    "#                 instance.append(idata['target'])\n",
    "#                 usage.append(h[0])\n",
    "#                 timestamps.append(h[1])\n",
    "#             #df['usage'] = usage\n",
    "#             #df['timestamp'] = timestamps\n",
    "# #     df['instance'] = instance\n",
    "# #     df['usage'] = usage\n",
    "# #     df['timestamp'] = timestamps        \n",
    "# #     df = pd.concat([instance, usage, timestamps], axis=1)    \n",
    "# #    print(len(instance),len(usage), len(timestamps))\n",
    "#         else:\n",
    "#             instance.append([])\n",
    "#             usage.append([])\n",
    "#             timestamps.append([])\n",
    "#     df = pd.DataFrame({'instance': instance, 'usage':usage, 'timestamp':timestamps})\n",
    "#     return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regex tests\n",
    "# target = data_json[87][0]['target']\n",
    "# instance = re.sub('\\_com.*', '', target)\n",
    "# instance = instance+'.com'\n",
    "# instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests for date\n",
    "# ts = logData.timestamp[0]\n",
    "# ts2 = logData.timestamp[1]\n",
    "\n",
    "\n",
    "# readable = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %X')\n",
    "# readable2 = datetime.datetime.fromtimestamp(ts2).strftime('%Y-%m-%d %X')\n",
    "# #.isoformat()\n",
    "# # datetime.datetime.strptime(readable, '%Y\n",
    "# datetime.datetime.strptime(readable2)-datetime.datetime.strptime(readable2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more regex testing\n",
    "# e = 'DEV0.domain.CSSAPPS.infra_service.EC2.cssapps001_da_aws_cccis_com'\n",
    "# e = re.sub(r'.+EC2.','',e)\n",
    "# e = re.sub('_', '.', e)\n",
    "# e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
